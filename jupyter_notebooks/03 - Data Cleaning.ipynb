{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Cleaning Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Evaluate missing data\n",
        "*   Clean data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HeritageHousing.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "  * Cleaned Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/HeritageHousing.csv\")\n",
        "    )\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictive Power Score and Correlation Study\n",
        "\n",
        "Let's run some more analysis on the data before we continue, so we can look at how the missing data correlates with the rest of our data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
        "                  df_corr_spearman=df_corr_spearman, \n",
        "                  pps_matrix=pps_matrix,\n",
        "                  CorrThreshold=0.6, PPS_Threshold=0.15,\n",
        "                  figsize=(10,10), font_annot=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's remind ourselves of the columns that have missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "  missing_data_absolute = df.isnull().sum()\n",
        "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
        "  df_missing_data = (pd.DataFrame(\n",
        "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                 \"DataType\":df.dtypes}\n",
        "                                  )\n",
        "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can discuss what changes we want to make to each of the variables and their missing data.\n",
        "\n",
        "First we will want to use an ArbitraryNumberImputer function to replace the missing data of `2ndFlrSF`, `EnclosedPorch`, `MasVnrArea` and `WoodDeckSF` with 0 as it is the most common value for all of these variables. It's safer to assume that a missing value for these variables means that the house simply doesn't have one of those features. For example, `EnclosedPorch` is missing 90.7% and 7.9% of the data that we do have is 0 meaning that for more than 80% of the data that we do have the value is 0.\n",
        "\n",
        "In most cases it's fine to drop columns that are missing 80% or more of their data. But we know that a houses size is one of the greatest predictors of Sale Price and want to see if we can gain a better PPS by combining all the variables related to the houses size once the data is cleaned.\n",
        "\n",
        "The other variable related to the size of the house is `LotFrontage`. With the pandas profile report in the last notebook, we can see that this data is much closer to being normally distributed and so, we will use the MeanMedianImputer function to impute the NaN values with a median value.\n",
        "\n",
        "---\n",
        "\n",
        "Next is `Bedroom Above Grade`. We don't know what the 'grade' is and this column is missing just a bit more information than we would like to be able to drop all the rows. Perhaps with more understanding of what the variable is, we could estimate the number of Bedrooms above grade based on other houses vs their overall size and perhaps quality. For now though we'll use the MeanMedianImputer. \n",
        "\n",
        "---\n",
        "\n",
        "Then there are two columns of missing data for the garages, `GarageFinish` and `GarageYrBlt`. Let's take one more look at them, along with `YearBuilt`(of the house) and `GarageArea`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_nan_finish = df[df['GarageFinish'].isna()]\n",
        "df_nan_finish[['GarageFinish','GarageYrBlt', 'GarageArea', 'YearBuilt']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_nan_year = df[df['GarageYrBlt'].isna()]\n",
        "df_nan_year[['GarageFinish','GarageYrBlt', 'GarageArea']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And two last things to check, `GarageFinish` and `BasementFinish` where the value is missing and the area of the related feature is 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_compare1 = df.loc[(df['GarageFinish'].isna()) & (df['GarageArea'] == 0)]\n",
        "df_compare1[['GarageFinish', 'GarageArea']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_compare2 = df.loc[(df['BsmtFinType1'].isna()) & (df['TotalBsmtSF'] == 0)]\n",
        "df_compare2[['BsmtFinType1', 'TotalBsmtSF']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There doesn't seem to be any clear indicator of what the best way to set the `GarageFinish` as would be. \n",
        "It also showed little to no correlation against the sale price in our initial study of the data we can fill the missing data with `Unf`. Some of the `GarageFinish` missing values do share a `GarageArea` of 0, which means ideally we would for these cases fill them with `None` instead. But as it's only for 8 of the missing values we're happy to skip over this for now.\n",
        "Using the PPS we see there is moderate correlation between `GarageFinish`, `Overall Quality`, `YearBuilt` and others. So in future we could perhaps predict what `GarageFinish` should be based on other variables to improve our model. But for now we're happy to use the frequent category as our imputation method by using the CategoricalVariableImputer function. \n",
        "\n",
        "---\n",
        "\n",
        "We'll use the same reasoning and imputation method as `GarageFinish` for `BsmtFinType1`, using `Unf` for any missing data. We dont need to fill any of the values with `None` for this variable, as we checked that all the missing values do have a `TotalBsmtSF` \n",
        "\n",
        "---\n",
        "\n",
        "And for `GarageYrBlt` we can see the NaN values are appearing where a house doesn't have a garage. \n",
        "We can't set this value to 0 but there's a clear indication that most houses are built with a garage as they typically have the same `YearBuilt` and `GarageYrBlt` dates.\n",
        "So for this we'll replace any missing values with the date the year the house was built.\n",
        "\n",
        "![DataCleaningSpreadsheet](../media/DataCleaning.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we clean the data, we will use a function built by Code Institue. This will perform the imputations using imputation methods from feature engine and then plot the original and cleaned datasets against each other to help visualise the effect our changes will have on the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we set up the parameters for the cleaning functions and run them. First is the AbritraryNumberImputer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "\n",
        "variables_method = ['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF']\n",
        "variables_method\n",
        "\n",
        "imputer = ArbitraryNumberImputer(arbitrary_number=0, variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next is the `LotFrontage` and `BedroomAbvGr` for which we use the MeanMedianImputer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "variables_method = ['LotFrontage', 'BedroomAbvGr']\n",
        "variables_method\n",
        "\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The CategoricalImputer for `GarageFinish` and `BsmtFinType1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "variables_method = ['GarageFinish', 'BsmtFinType1']\n",
        "variables_method\n",
        "\n",
        "imputer = CategoricalImputer(imputation_method='missing',fill_value='Unf',\n",
        "                             variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And last, the `GarageYrBlt`. We don't have a feature engine imputer for this one so we will have to use a rudimentary way to show the difference. As we mentioned, the `GarageYrBlt` is almost always the same as the `YearBuilt`. So with this variable and imputation method the difference in change is difficult to see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "before_garage_impute = df\n",
        "df['GarageYrBlt'].fillna(df['YearBuilt'])\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "before_garage_impute['GarageYrBlt'].plot(kind='kde', ax=ax, linewidth=5)\n",
        "df['GarageYrBlt'].plot(kind='kde', ax=ax, color='red')\n",
        "lines, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(lines, labels, loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply the Changes to the Missing Data\n",
        "\n",
        "If we were removing any rows from our data, we would also check the data again during this stage as it would likely alter the distribution on some of the variables we are cleaning. \n",
        "As this is not the case, we can be sure that our analysis of how the data changes from cleaning will remain the same as our earlier study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_method = ['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF']\n",
        "imputer = ArbitraryNumberImputer(arbitrary_number=0, variables=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_method = ['LotFrontage', 'BedroomAbvGr']\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_method = ['GarageFinish', 'BsmtFinType1']\n",
        "imputer = CategoricalImputer(imputation_method='missing',fill_value='Unf',\n",
        "                             variables=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet['GarageYrBlt'].fillna(df['YearBuilt'], inplace=True)\n",
        "TestSet['GarageYrBlt'].fillna(df['YearBuilt'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(TrainSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(TestSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
